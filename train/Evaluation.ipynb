{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloudWine Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the runs folder\n",
    "!rm ./runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_config():\n",
    "    config = {\n",
    "      \"model\": \"\",\n",
    "      \"args\": {\n",
    "        \"data_path\": \"./data/raw/sample.csv\",\n",
    "        \"lowercase\": False,\n",
    "        \"remove_punctuation\": False,\n",
    "        \"remove_stopwords\": False,\n",
    "        \"lemmatize\": False,\n",
    "        \"save_model\": False,\n",
    "        \"model_dir\": \"./models/\",\n",
    "        \"save_validation\": True,\n",
    "        \"validation_dir\": \"./runs/\"\n",
    "      }\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(config, model):\n",
    "    config['model'] = model\n",
    "    return config\n",
    "    \n",
    "def set_nlp_args(config, preprocess):\n",
    "    config['args']['lowercase'] = preprocess\n",
    "    config['args']['remove_punctuation'] = preprocess\n",
    "    config['args']['remove_stopwords'] = preprocess\n",
    "    config['args']['lemmatize'] = preprocess\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['tfidf', 'doc2vec', 'bert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model tfidf\n",
      "[nltk_data] Downloading package stopwords to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2020-06-11 14:47:03,990 gensim.corpora.dictionary INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-11 14:47:03,991 gensim.corpora.dictionary INFO     built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-06-11 14:47:04,222 transformers.file_utils INFO     PyTorch version 1.5.0 available.\n",
      "2020-06-11 14:47:04,297 root         INFO     {'data_path': './data/raw/sample.csv', 'lemmatize': False, 'lowercase': False, 'model_dir': './models/', 'remove_punctuation': False, 'remove_stopwords': False, 'save_model': False, 'save_validation': True, 'validation_dir': './runs/'}\n",
      "2020-06-11 14:47:04,297 root         INFO     Loading data from ./data/raw/sample.csv\n",
      "2020-06-11 14:47:04,356 root         INFO     Training TF-IDF model\n",
      "2020-06-11 14:47:04,503 root         INFO     Calculating cluster similarities\n",
      "2020-06-11 14:47:04,517 root         INFO     \n",
      "\n",
      "2020-06-11 14:47:04,517 root         INFO     Saving Validation\n",
      "[nltk_data] Downloading package stopwords to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2020-06-11 14:47:07,093 gensim.corpora.dictionary INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-11 14:47:07,093 gensim.corpora.dictionary INFO     built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-06-11 14:47:07,330 transformers.file_utils INFO     PyTorch version 1.5.0 available.\n",
      "2020-06-11 14:47:07,411 root         INFO     {'data_path': './data/raw/sample.csv', 'lemmatize': True, 'lowercase': True, 'model_dir': './models/', 'remove_punctuation': True, 'remove_stopwords': True, 'save_model': False, 'save_validation': True, 'validation_dir': './runs/'}\n",
      "2020-06-11 14:47:07,411 root         INFO     Loading data from ./data/raw/sample.csv\n",
      "2020-06-11 14:47:07,464 root         INFO     Converting to lowercase\n",
      "2020-06-11 14:47:07,465 root         INFO     Removing punctuation\n",
      "2020-06-11 14:47:07,471 root         INFO     Removing stopwords\n",
      "2020-06-11 14:47:07,633 root         INFO     Lemmatizing\n",
      "2020-06-11 14:47:09,178 root         INFO     Training TF-IDF model\n",
      "2020-06-11 14:47:09,279 root         INFO     Calculating cluster similarities\n",
      "2020-06-11 14:47:09,291 root         INFO     \n",
      "\n",
      "2020-06-11 14:47:09,291 root         INFO     Saving Validation\n",
      "Running model doc2vec\n",
      "[nltk_data] Downloading package stopwords to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2020-06-11 14:47:12,155 gensim.corpora.dictionary INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-11 14:47:12,156 gensim.corpora.dictionary INFO     built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-06-11 14:47:12,416 transformers.file_utils INFO     PyTorch version 1.5.0 available.\n",
      "2020-06-11 14:47:12,493 root         INFO     {'data_path': './data/raw/sample.csv', 'lemmatize': False, 'lowercase': False, 'model_dir': './models/', 'remove_punctuation': False, 'remove_stopwords': False, 'save_model': False, 'save_validation': True, 'validation_dir': './runs/'}\n",
      "2020-06-11 14:47:12,494 root         INFO     Loading data from ./data/raw/sample.csv\n",
      "2020-06-11 14:47:12,555 root         INFO     Training Doc2Vec model\n",
      "/opt/anaconda3/envs/cloudwine/lib/python3.8/site-packages/gensim/models/doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2020-06-11 14:47:12,557 gensim.models.doc2vec INFO     collecting all words and their counts\n",
      "2020-06-11 14:47:12,557 gensim.models.doc2vec WARNING  Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2020-06-11 14:47:12,557 gensim.models.doc2vec INFO     PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-06-11 14:47:12,579 gensim.models.doc2vec INFO     collected 95 word types and 834 unique tags from a corpus of 834 examples and 200137 words\n",
      "2020-06-11 14:47:12,579 gensim.models.word2vec INFO     Loading a fresh vocabulary\n",
      "2020-06-11 14:47:12,580 gensim.models.word2vec INFO     effective_min_count=1 retains 95 unique words (100% of original 95, drops 0)\n",
      "2020-06-11 14:47:12,580 gensim.models.word2vec INFO     effective_min_count=1 leaves 200137 word corpus (100% of original 200137, drops 0)\n",
      "2020-06-11 14:47:12,580 gensim.models.word2vec INFO     deleting the raw counts dictionary of 95 items\n",
      "2020-06-11 14:47:12,580 gensim.models.word2vec INFO     sample=0.001 downsamples 26 most-common words\n",
      "2020-06-11 14:47:12,580 gensim.models.word2vec INFO     downsampling leaves estimated 40137 word corpus (20.1% of prior 200137)\n",
      "2020-06-11 14:47:12,581 gensim.models.base_any2vec INFO     estimated required memory for 95 words and 768 dimensions: 3360028 bytes\n",
      "2020-06-11 14:47:12,581 gensim.models.word2vec INFO     resetting layer weights\n",
      "2020-06-11 14:47:12,783 root         INFO     iteration 0\n",
      "0/10\n",
      "2020-06-11 14:47:12,783 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:12,896 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:12,903 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:12,906 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:12,906 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (40856 effective words) took 0.1s, 334845 effective words/s\n",
      "2020-06-11 14:47:13,038 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,043 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,044 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,044 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40951 effective words) took 0.1s, 301058 effective words/s\n",
      "2020-06-11 14:47:13,168 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,173 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,176 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,176 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (40914 effective words) took 0.1s, 313681 effective words/s\n",
      "2020-06-11 14:47:13,301 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,308 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,310 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,310 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (40778 effective words) took 0.1s, 306896 effective words/s\n",
      "2020-06-11 14:47:13,437 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,442 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,445 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,445 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (40800 effective words) took 0.1s, 307229 effective words/s\n",
      "2020-06-11 14:47:13,445 gensim.models.base_any2vec INFO     training on a 1000685 raw words (204299 effective words) took 0.7s, 308716 effective words/s\n",
      "2020-06-11 14:47:13,445 root         INFO     iteration 1\n",
      "1/10\n",
      "2020-06-11 14:47:13,445 gensim.models.base_any2vec WARNING  Effective 'alpha' higher than previous training cycles\n",
      "2020-06-11 14:47:13,445 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:13,578 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,586 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,589 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,589 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (41149 effective words) took 0.1s, 289930 effective words/s\n",
      "2020-06-11 14:47:13,722 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,729 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,731 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,731 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40981 effective words) took 0.1s, 292078 effective words/s\n",
      "2020-06-11 14:47:13,866 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:13,871 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:13,873 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:13,873 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (41278 effective words) took 0.1s, 294281 effective words/s\n",
      "2020-06-11 14:47:14,010 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,019 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,021 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,021 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (41087 effective words) took 0.1s, 280890 effective words/s\n",
      "2020-06-11 14:47:14,155 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,162 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,163 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,163 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (40962 effective words) took 0.1s, 290692 effective words/s\n",
      "2020-06-11 14:47:14,164 gensim.models.base_any2vec INFO     training on a 1000685 raw words (205457 effective words) took 0.7s, 285988 effective words/s\n",
      "2020-06-11 14:47:14,164 root         INFO     iteration 2\n",
      "2/10\n",
      "2020-06-11 14:47:14,164 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:14,298 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,305 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,306 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,306 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (41203 effective words) took 0.1s, 291419 effective words/s\n",
      "2020-06-11 14:47:14,435 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,440 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,442 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,442 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40997 effective words) took 0.1s, 305056 effective words/s\n",
      "2020-06-11 14:47:14,579 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,585 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,586 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,586 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (41125 effective words) took 0.1s, 288796 effective words/s\n",
      "2020-06-11 14:47:14,720 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,726 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,729 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,730 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (41088 effective words) took 0.1s, 288628 effective words/s\n",
      "2020-06-11 14:47:14,871 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:14,880 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:14,882 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:14,882 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (41233 effective words) took 0.2s, 273871 effective words/s\n",
      "2020-06-11 14:47:14,882 gensim.models.base_any2vec INFO     training on a 1000685 raw words (205646 effective words) took 0.7s, 286418 effective words/s\n",
      "2020-06-11 14:47:14,882 root         INFO     iteration 3\n",
      "3/10\n",
      "2020-06-11 14:47:14,882 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:15,018 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,026 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,027 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,027 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (41132 effective words) took 0.1s, 285981 effective words/s\n",
      "2020-06-11 14:47:15,160 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,167 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,169 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,169 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (41261 effective words) took 0.1s, 293673 effective words/s\n",
      "2020-06-11 14:47:15,305 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,314 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,314 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,314 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (40749 effective words) took 0.1s, 283633 effective words/s\n",
      "2020-06-11 14:47:15,448 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,456 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,457 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,458 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (40978 effective words) took 0.1s, 289667 effective words/s\n",
      "2020-06-11 14:47:15,599 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,605 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,607 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,608 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (41219 effective words) took 0.1s, 277597 effective words/s\n",
      "2020-06-11 14:47:15,608 gensim.models.base_any2vec INFO     training on a 1000685 raw words (205339 effective words) took 0.7s, 282945 effective words/s\n",
      "2020-06-11 14:47:15,608 root         INFO     iteration 4\n",
      "4/10\n",
      "2020-06-11 14:47:15,608 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:15,738 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,745 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,746 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,746 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (40952 effective words) took 0.1s, 299111 effective words/s\n",
      "2020-06-11 14:47:15,879 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:15,887 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:15,888 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:15,888 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (41050 effective words) took 0.1s, 291584 effective words/s\n",
      "2020-06-11 14:47:16,017 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,023 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,026 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,026 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (40917 effective words) took 0.1s, 300482 effective words/s\n",
      "2020-06-11 14:47:16,156 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,161 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,163 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,163 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (40834 effective words) took 0.1s, 300416 effective words/s\n",
      "2020-06-11 14:47:16,296 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,302 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,302 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,302 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (40956 effective words) took 0.1s, 297633 effective words/s\n",
      "2020-06-11 14:47:16,302 gensim.models.base_any2vec INFO     training on a 1000685 raw words (204709 effective words) took 0.7s, 294780 effective words/s\n",
      "2020-06-11 14:47:16,302 root         INFO     iteration 5\n",
      "5/10\n",
      "2020-06-11 14:47:16,303 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:16,432 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,438 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,439 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,439 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (40740 effective words) took 0.1s, 300787 effective words/s\n",
      "2020-06-11 14:47:16,567 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,574 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,576 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,576 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40763 effective words) took 0.1s, 300379 effective words/s\n",
      "2020-06-11 14:47:16,705 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,711 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,711 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,711 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (40943 effective words) took 0.1s, 307321 effective words/s\n",
      "2020-06-11 14:47:16,844 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,851 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,853 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,853 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (41165 effective words) took 0.1s, 293188 effective words/s\n",
      "2020-06-11 14:47:16,982 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:16,989 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:16,991 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:16,991 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (41092 effective words) took 0.1s, 299185 effective words/s\n",
      "2020-06-11 14:47:16,992 gensim.models.base_any2vec INFO     training on a 1000685 raw words (204703 effective words) took 0.7s, 297143 effective words/s\n",
      "2020-06-11 14:47:16,992 root         INFO     iteration 6\n",
      "6/10\n",
      "2020-06-11 14:47:16,992 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:17,122 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,129 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,130 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,131 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (41127 effective words) took 0.1s, 299329 effective words/s\n",
      "2020-06-11 14:47:17,263 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,268 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,271 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,271 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40870 effective words) took 0.1s, 293961 effective words/s\n",
      "2020-06-11 14:47:17,406 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,413 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,414 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,414 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (41027 effective words) took 0.1s, 290653 effective words/s\n",
      "2020-06-11 14:47:17,542 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,551 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,552 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,552 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (41060 effective words) took 0.1s, 299422 effective words/s\n",
      "2020-06-11 14:47:17,686 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,692 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,694 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,694 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (41290 effective words) took 0.1s, 294910 effective words/s\n",
      "2020-06-11 14:47:17,694 gensim.models.base_any2vec INFO     training on a 1000685 raw words (205374 effective words) took 0.7s, 292559 effective words/s\n",
      "2020-06-11 14:47:17,694 root         INFO     iteration 7\n",
      "7/10\n",
      "2020-06-11 14:47:17,694 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:17,826 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,830 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,833 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,833 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (41337 effective words) took 0.1s, 299740 effective words/s\n",
      "2020-06-11 14:47:17,977 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:17,980 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:17,984 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:17,984 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40618 effective words) took 0.1s, 273106 effective words/s\n",
      "2020-06-11 14:47:18,123 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,130 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,131 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,131 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (40970 effective words) took 0.1s, 281743 effective words/s\n",
      "2020-06-11 14:47:18,263 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,268 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,270 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,270 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (40959 effective words) took 0.1s, 297389 effective words/s\n",
      "2020-06-11 14:47:18,407 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,411 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,414 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,414 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (40637 effective words) took 0.1s, 284637 effective words/s\n",
      "2020-06-11 14:47:18,414 gensim.models.base_any2vec INFO     training on a 1000685 raw words (204521 effective words) took 0.7s, 283876 effective words/s\n",
      "2020-06-11 14:47:18,415 root         INFO     iteration 8\n",
      "8/10\n",
      "2020-06-11 14:47:18,415 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:18,542 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,545 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,551 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,552 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (40692 effective words) took 0.1s, 300357 effective words/s\n",
      "2020-06-11 14:47:18,693 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,700 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,701 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,701 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (40720 effective words) took 0.1s, 274440 effective words/s\n",
      "2020-06-11 14:47:18,837 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,842 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,844 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,844 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (41137 effective words) took 0.1s, 290341 effective words/s\n",
      "2020-06-11 14:47:18,971 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:18,976 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:18,978 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:18,978 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (40765 effective words) took 0.1s, 307752 effective words/s\n",
      "2020-06-11 14:47:19,131 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:19,139 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:19,142 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:19,142 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (40917 effective words) took 0.2s, 251883 effective words/s\n",
      "2020-06-11 14:47:19,142 gensim.models.base_any2vec INFO     training on a 1000685 raw words (204231 effective words) took 0.7s, 280765 effective words/s\n",
      "2020-06-11 14:47:19,142 root         INFO     iteration 9\n",
      "9/10\n",
      "2020-06-11 14:47:19,142 gensim.models.base_any2vec INFO     training model with 3 workers on 95 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:19,300 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:19,306 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:19,306 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:19,307 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 200137 raw words (40759 effective words) took 0.2s, 250265 effective words/s\n",
      "2020-06-11 14:47:19,446 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:19,455 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:19,457 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:19,457 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 200137 raw words (41019 effective words) took 0.1s, 275612 effective words/s\n",
      "2020-06-11 14:47:19,613 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:19,615 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:19,617 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:19,617 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 200137 raw words (40998 effective words) took 0.2s, 259230 effective words/s\n",
      "2020-06-11 14:47:19,758 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:19,766 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:19,767 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:19,768 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 200137 raw words (40975 effective words) took 0.1s, 274369 effective words/s\n",
      "2020-06-11 14:47:19,919 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:19,923 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:19,924 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:19,924 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 200137 raw words (40830 effective words) took 0.2s, 264860 effective words/s\n",
      "2020-06-11 14:47:19,924 gensim.models.base_any2vec INFO     training on a 1000685 raw words (204581 effective words) took 0.8s, 261833 effective words/s\n",
      "2020-06-11 14:47:21,325 root         INFO     Calculating cluster similarities\n",
      "2020-06-11 14:47:21,339 root         INFO     \n",
      "\n",
      "2020-06-11 14:47:21,339 root         INFO     Saving Validation\n",
      "[nltk_data] Downloading package stopwords to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2020-06-11 14:47:24,151 gensim.corpora.dictionary INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-11 14:47:24,151 gensim.corpora.dictionary INFO     built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-06-11 14:47:24,453 transformers.file_utils INFO     PyTorch version 1.5.0 available.\n",
      "2020-06-11 14:47:24,547 root         INFO     {'data_path': './data/raw/sample.csv', 'lemmatize': True, 'lowercase': True, 'model_dir': './models/', 'remove_punctuation': True, 'remove_stopwords': True, 'save_model': False, 'save_validation': True, 'validation_dir': './runs/'}\n",
      "2020-06-11 14:47:24,547 root         INFO     Loading data from ./data/raw/sample.csv\n",
      "2020-06-11 14:47:24,614 root         INFO     Converting to lowercase\n",
      "2020-06-11 14:47:24,615 root         INFO     Removing punctuation\n",
      "2020-06-11 14:47:24,622 root         INFO     Removing stopwords\n",
      "2020-06-11 14:47:24,829 root         INFO     Lemmatizing\n",
      "2020-06-11 14:47:26,566 root         INFO     Training Doc2Vec model\n",
      "/opt/anaconda3/envs/cloudwine/lib/python3.8/site-packages/gensim/models/doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2020-06-11 14:47:26,568 gensim.models.doc2vec INFO     collecting all words and their counts\n",
      "2020-06-11 14:47:26,568 gensim.models.doc2vec WARNING  Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2020-06-11 14:47:26,569 gensim.models.doc2vec INFO     PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-06-11 14:47:26,587 gensim.models.doc2vec INFO     collected 49 word types and 834 unique tags from a corpus of 834 examples and 142895 words\n",
      "2020-06-11 14:47:26,587 gensim.models.word2vec INFO     Loading a fresh vocabulary\n",
      "2020-06-11 14:47:26,587 gensim.models.word2vec INFO     effective_min_count=1 retains 49 unique words (100% of original 49, drops 0)\n",
      "2020-06-11 14:47:26,587 gensim.models.word2vec INFO     effective_min_count=1 leaves 142895 word corpus (100% of original 142895, drops 0)\n",
      "2020-06-11 14:47:26,587 gensim.models.word2vec INFO     deleting the raw counts dictionary of 49 items\n",
      "2020-06-11 14:47:26,588 gensim.models.word2vec INFO     sample=0.001 downsamples 23 most-common words\n",
      "2020-06-11 14:47:26,588 gensim.models.word2vec INFO     downsampling leaves estimated 25478 word corpus (17.8% of prior 142895)\n",
      "2020-06-11 14:47:26,588 gensim.models.base_any2vec INFO     estimated required memory for 49 words and 768 dimensions: 3054404 bytes\n",
      "2020-06-11 14:47:26,588 gensim.models.word2vec INFO     resetting layer weights\n",
      "2020-06-11 14:47:26,798 root         INFO     iteration 0\n",
      "0/10\n",
      "2020-06-11 14:47:26,798 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:26,875 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:26,882 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:26,882 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:26,882 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26202 effective words) took 0.1s, 316777 effective words/s\n",
      "2020-06-11 14:47:26,994 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,000 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,001 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,001 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26331 effective words) took 0.1s, 224428 effective words/s\n",
      "2020-06-11 14:47:27,111 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,113 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,114 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,114 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26398 effective words) took 0.1s, 238135 effective words/s\n",
      "2020-06-11 14:47:27,218 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,225 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,226 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,226 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26482 effective words) took 0.1s, 239754 effective words/s\n",
      "2020-06-11 14:47:27,333 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,337 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,340 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,340 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26339 effective words) took 0.1s, 236020 effective words/s\n",
      "2020-06-11 14:47:27,340 gensim.models.base_any2vec INFO     training on a 714475 raw words (131752 effective words) took 0.5s, 243263 effective words/s\n",
      "2020-06-11 14:47:27,340 root         INFO     iteration 1\n",
      "1/10\n",
      "2020-06-11 14:47:27,340 gensim.models.base_any2vec WARNING  Effective 'alpha' higher than previous training cycles\n",
      "2020-06-11 14:47:27,340 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:27,438 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,443 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,445 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,445 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26270 effective words) took 0.1s, 254990 effective words/s\n",
      "2020-06-11 14:47:27,546 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,551 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,552 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,552 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26368 effective words) took 0.1s, 249817 effective words/s\n",
      "2020-06-11 14:47:27,654 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,658 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,659 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,659 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26372 effective words) took 0.1s, 249996 effective words/s\n",
      "2020-06-11 14:47:27,772 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,776 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,779 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,779 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26024 effective words) took 0.1s, 220053 effective words/s\n",
      "2020-06-11 14:47:27,878 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:27,884 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:27,885 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:27,886 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26058 effective words) took 0.1s, 247928 effective words/s\n",
      "2020-06-11 14:47:27,886 gensim.models.base_any2vec INFO     training on a 714475 raw words (131092 effective words) took 0.5s, 240369 effective words/s\n",
      "2020-06-11 14:47:27,886 root         INFO     iteration 2\n",
      "2/10\n",
      "2020-06-11 14:47:27,886 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:28,006 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,010 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,011 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,011 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26581 effective words) took 0.1s, 214984 effective words/s\n",
      "2020-06-11 14:47:28,122 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,126 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,127 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,127 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26072 effective words) took 0.1s, 228732 effective words/s\n",
      "2020-06-11 14:47:28,229 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,232 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,235 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,235 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26121 effective words) took 0.1s, 243927 effective words/s\n",
      "2020-06-11 14:47:28,330 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,334 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,337 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,337 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26559 effective words) took 0.1s, 266624 effective words/s\n",
      "2020-06-11 14:47:28,435 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,442 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,442 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,442 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26599 effective words) took 0.1s, 255318 effective words/s\n",
      "2020-06-11 14:47:28,443 gensim.models.base_any2vec INFO     training on a 714475 raw words (131932 effective words) took 0.6s, 237008 effective words/s\n",
      "2020-06-11 14:47:28,443 root         INFO     iteration 3\n",
      "3/10\n",
      "2020-06-11 14:47:28,443 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:28,540 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,544 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,546 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,546 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26529 effective words) took 0.1s, 259990 effective words/s\n",
      "2020-06-11 14:47:28,643 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,647 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,648 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,649 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26370 effective words) took 0.1s, 261899 effective words/s\n",
      "2020-06-11 14:47:28,749 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,756 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,756 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,756 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26292 effective words) took 0.1s, 248011 effective words/s\n",
      "2020-06-11 14:47:28,852 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,859 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,860 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,860 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26228 effective words) took 0.1s, 256101 effective words/s\n",
      "2020-06-11 14:47:28,957 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:28,964 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:28,965 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:28,965 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26380 effective words) took 0.1s, 254898 effective words/s\n",
      "2020-06-11 14:47:28,965 gensim.models.base_any2vec INFO     training on a 714475 raw words (131799 effective words) took 0.5s, 252454 effective words/s\n",
      "2020-06-11 14:47:28,965 root         INFO     iteration 4\n",
      "4/10\n",
      "2020-06-11 14:47:28,965 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:29,081 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,086 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,087 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,087 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26371 effective words) took 0.1s, 219692 effective words/s\n",
      "2020-06-11 14:47:29,186 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,193 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,194 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,194 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26253 effective words) took 0.1s, 247756 effective words/s\n",
      "2020-06-11 14:47:29,298 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,306 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,307 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,307 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26310 effective words) took 0.1s, 236586 effective words/s\n",
      "2020-06-11 14:47:29,405 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,412 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,413 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,413 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26521 effective words) took 0.1s, 254379 effective words/s\n",
      "2020-06-11 14:47:29,507 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,513 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,514 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,514 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26470 effective words) took 0.1s, 265157 effective words/s\n",
      "2020-06-11 14:47:29,514 gensim.models.base_any2vec INFO     training on a 714475 raw words (131925 effective words) took 0.5s, 240213 effective words/s\n",
      "2020-06-11 14:47:29,514 root         INFO     iteration 5\n",
      "5/10\n",
      "2020-06-11 14:47:29,515 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:29,609 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,613 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,614 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,614 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (25975 effective words) took 0.1s, 264372 effective words/s\n",
      "2020-06-11 14:47:29,716 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,720 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,723 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,723 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26412 effective words) took 0.1s, 246991 effective words/s\n",
      "2020-06-11 14:47:29,815 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,819 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,822 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,822 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26364 effective words) took 0.1s, 271264 effective words/s\n",
      "2020-06-11 14:47:29,919 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:29,927 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:29,928 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:29,928 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26365 effective words) took 0.1s, 251773 effective words/s\n",
      "2020-06-11 14:47:30,025 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,029 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,030 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,030 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26287 effective words) took 0.1s, 261284 effective words/s\n",
      "2020-06-11 14:47:30,030 gensim.models.base_any2vec INFO     training on a 714475 raw words (131403 effective words) took 0.5s, 254826 effective words/s\n",
      "2020-06-11 14:47:30,030 root         INFO     iteration 6\n",
      "6/10\n",
      "2020-06-11 14:47:30,030 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:30,141 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,146 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,147 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,147 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26260 effective words) took 0.1s, 227671 effective words/s\n",
      "2020-06-11 14:47:30,241 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,248 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,249 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,249 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26390 effective words) took 0.1s, 263893 effective words/s\n",
      "2020-06-11 14:47:30,348 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,351 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,354 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,354 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26114 effective words) took 0.1s, 252172 effective words/s\n",
      "2020-06-11 14:47:30,456 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,463 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,464 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,464 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26526 effective words) took 0.1s, 245320 effective words/s\n",
      "2020-06-11 14:47:30,561 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,566 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,567 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,568 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26249 effective words) took 0.1s, 256304 effective words/s\n",
      "2020-06-11 14:47:30,568 gensim.models.base_any2vec INFO     training on a 714475 raw words (131539 effective words) took 0.5s, 244900 effective words/s\n",
      "2020-06-11 14:47:30,568 root         INFO     iteration 7\n",
      "7/10\n",
      "2020-06-11 14:47:30,568 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:30,667 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,675 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,676 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,676 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26347 effective words) took 0.1s, 247638 effective words/s\n",
      "2020-06-11 14:47:30,777 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,783 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,784 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,784 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26250 effective words) took 0.1s, 245863 effective words/s\n",
      "2020-06-11 14:47:30,879 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,883 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,884 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,884 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26441 effective words) took 0.1s, 268828 effective words/s\n",
      "2020-06-11 14:47:30,986 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:30,992 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:30,993 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:30,993 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26380 effective words) took 0.1s, 245591 effective words/s\n",
      "2020-06-11 14:47:31,088 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,092 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,094 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,094 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26016 effective words) took 0.1s, 261788 effective words/s\n",
      "2020-06-11 14:47:31,094 gensim.models.base_any2vec INFO     training on a 714475 raw words (131434 effective words) took 0.5s, 249768 effective words/s\n",
      "2020-06-11 14:47:31,094 root         INFO     iteration 8\n",
      "8/10\n",
      "2020-06-11 14:47:31,094 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:31,204 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,210 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,211 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,211 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26307 effective words) took 0.1s, 228831 effective words/s\n",
      "2020-06-11 14:47:31,306 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,313 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,314 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,314 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26256 effective words) took 0.1s, 258528 effective words/s\n",
      "2020-06-11 14:47:31,410 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,415 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,416 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,416 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26341 effective words) took 0.1s, 263937 effective words/s\n",
      "2020-06-11 14:47:31,517 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,523 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,523 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,523 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26284 effective words) took 0.1s, 247299 effective words/s\n",
      "2020-06-11 14:47:31,630 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,634 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,635 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,636 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26337 effective words) took 0.1s, 238204 effective words/s\n",
      "2020-06-11 14:47:31,636 gensim.models.base_any2vec INFO     training on a 714475 raw words (131525 effective words) took 0.5s, 242995 effective words/s\n",
      "2020-06-11 14:47:31,636 root         INFO     iteration 9\n",
      "9/10\n",
      "2020-06-11 14:47:31,636 gensim.models.base_any2vec INFO     training model with 3 workers on 49 vocabulary and 768 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-11 14:47:31,730 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,739 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,739 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,739 gensim.models.base_any2vec INFO     EPOCH - 1 : training on 142895 raw words (26088 effective words) took 0.1s, 255335 effective words/s\n",
      "2020-06-11 14:47:31,834 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,842 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,843 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,843 gensim.models.base_any2vec INFO     EPOCH - 2 : training on 142895 raw words (26280 effective words) took 0.1s, 258477 effective words/s\n",
      "2020-06-11 14:47:31,950 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:31,956 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:31,958 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:31,958 gensim.models.base_any2vec INFO     EPOCH - 3 : training on 142895 raw words (26519 effective words) took 0.1s, 232383 effective words/s\n",
      "2020-06-11 14:47:32,061 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:32,068 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:32,069 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:32,069 gensim.models.base_any2vec INFO     EPOCH - 4 : training on 142895 raw words (26307 effective words) took 0.1s, 241781 effective words/s\n",
      "2020-06-11 14:47:32,164 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-11 14:47:32,169 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-11 14:47:32,170 gensim.models.base_any2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-11 14:47:32,171 gensim.models.base_any2vec INFO     EPOCH - 5 : training on 142895 raw words (26459 effective words) took 0.1s, 264319 effective words/s\n",
      "2020-06-11 14:47:32,171 gensim.models.base_any2vec INFO     training on a 714475 raw words (131653 effective words) took 0.5s, 246179 effective words/s\n",
      "2020-06-11 14:47:33,562 root         INFO     Calculating cluster similarities\n",
      "2020-06-11 14:47:33,577 root         INFO     \n",
      "\n",
      "2020-06-11 14:47:33,577 root         INFO     Saving Validation\n",
      "Running model bert\n",
      "[nltk_data] Downloading package stopwords to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2020-06-11 14:47:36,624 gensim.corpora.dictionary INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-11 14:47:36,624 gensim.corpora.dictionary INFO     built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-06-11 14:47:36,906 transformers.file_utils INFO     PyTorch version 1.5.0 available.\n",
      "2020-06-11 14:47:36,993 root         INFO     Load pretrained SentenceTransformer: bert-base-nli-mean-tokens\n",
      "2020-06-11 14:47:36,993 root         INFO     Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "2020-06-11 14:47:36,994 root         INFO     Load SentenceTransformer from folder: /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\n",
      "2020-06-11 14:47:37,002 transformers.configuration_utils INFO     loading configuration file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/config.json\n",
      "2020-06-11 14:47:37,003 transformers.configuration_utils INFO     Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-06-11 14:47:37,003 transformers.modeling_utils INFO     loading weights file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/pytorch_model.bin\n",
      "2020-06-11 14:47:39,020 transformers.tokenization_utils INFO     Model name '/Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '/Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-06-11 14:47:39,021 transformers.tokenization_utils INFO     Didn't find file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/tokenizer_config.json. We won't load it.\n",
      "2020-06-11 14:47:39,021 transformers.tokenization_utils INFO     loading file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/vocab.txt\n",
      "2020-06-11 14:47:39,021 transformers.tokenization_utils INFO     loading file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/added_tokens.json\n",
      "2020-06-11 14:47:39,021 transformers.tokenization_utils INFO     loading file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/special_tokens_map.json\n",
      "2020-06-11 14:47:39,021 transformers.tokenization_utils INFO     loading file None\n",
      "2020-06-11 14:47:39,119 root         INFO     Use pytorch device: cpu\n",
      "2020-06-11 14:47:39,121 root         INFO     {'data_path': './data/raw/sample.csv', 'lemmatize': False, 'lowercase': False, 'model_dir': './models/', 'remove_punctuation': False, 'remove_stopwords': False, 'save_model': False, 'save_validation': True, 'validation_dir': './runs/'}\n",
      "2020-06-11 14:47:39,121 root         INFO     Loading data from ./data/raw/sample.csv\n",
      "2020-06-11 14:47:39,182 root         INFO     Training BERT model\n",
      "Encoding bert embeddings\n",
      "Batches: 100%|| 105/105 [02:02<00:00,  1.17s/it]\n",
      "2020-06-11 14:49:42,099 root         INFO     Calculating cluster similarities\n",
      "2020-06-11 14:49:42,132 root         INFO     \n",
      "\n",
      "2020-06-11 14:49:42,132 root         INFO     Saving Validation\n",
      "[nltk_data] Downloading package stopwords to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2020-06-11 14:49:45,383 gensim.corpora.dictionary INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-11 14:49:45,384 gensim.corpora.dictionary INFO     built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-06-11 14:49:45,641 transformers.file_utils INFO     PyTorch version 1.5.0 available.\n",
      "2020-06-11 14:49:45,725 root         INFO     Load pretrained SentenceTransformer: bert-base-nli-mean-tokens\n",
      "2020-06-11 14:49:45,725 root         INFO     Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "2020-06-11 14:49:45,725 root         INFO     Load SentenceTransformer from folder: /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\n",
      "2020-06-11 14:49:45,734 transformers.configuration_utils INFO     loading configuration file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/config.json\n",
      "2020-06-11 14:49:45,734 transformers.configuration_utils INFO     Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-06-11 14:49:45,734 transformers.modeling_utils INFO     loading weights file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/pytorch_model.bin\n",
      "2020-06-11 14:49:47,907 transformers.tokenization_utils INFO     Model name '/Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '/Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-06-11 14:49:47,908 transformers.tokenization_utils INFO     Didn't find file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/tokenizer_config.json. We won't load it.\n",
      "2020-06-11 14:49:47,908 transformers.tokenization_utils INFO     loading file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/vocab.txt\n",
      "2020-06-11 14:49:47,908 transformers.tokenization_utils INFO     loading file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/added_tokens.json\n",
      "2020-06-11 14:49:47,908 transformers.tokenization_utils INFO     loading file /Users/elmi/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/0_BERT/special_tokens_map.json\n",
      "2020-06-11 14:49:47,908 transformers.tokenization_utils INFO     loading file None\n",
      "2020-06-11 14:49:48,037 root         INFO     Use pytorch device: cpu\n",
      "2020-06-11 14:49:48,044 root         INFO     {'data_path': './data/raw/sample.csv', 'lemmatize': True, 'lowercase': True, 'model_dir': './models/', 'remove_punctuation': True, 'remove_stopwords': True, 'save_model': False, 'save_validation': True, 'validation_dir': './runs/'}\n",
      "2020-06-11 14:49:48,044 root         INFO     Loading data from ./data/raw/sample.csv\n",
      "2020-06-11 14:49:48,192 root         INFO     Converting to lowercase\n",
      "2020-06-11 14:49:48,195 root         INFO     Removing punctuation\n",
      "2020-06-11 14:49:48,208 root         INFO     Removing stopwords\n",
      "2020-06-11 14:49:48,518 root         INFO     Lemmatizing\n",
      "2020-06-11 14:49:50,773 root         INFO     Training BERT model\n",
      "Encoding bert embeddings\n",
      "Batches: 100%|| 105/105 [01:05<00:00,  1.61it/s]\n",
      "2020-06-11 14:50:56,032 root         INFO     Calculating cluster similarities\n",
      "2020-06-11 14:50:56,066 root         INFO     \n",
      "\n",
      "2020-06-11 14:50:56,066 root         INFO     Saving Validation\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print('Running model ' + m)\n",
    "    config = reset_config()\n",
    "    config = set_model(config, m)\n",
    "    config = set_nlp_args(config, False)\n",
    "\n",
    "    with open('./config.yaml', \"w\") as ff:\n",
    "        yaml.dump(config, ff, default_flow_style=False)\n",
    "\n",
    "    !python3 train.py -y './config.yaml'\n",
    "    \n",
    "    config = reset_config()\n",
    "    config = set_model(config, m)\n",
    "    config = set_nlp_args(config, True)\n",
    "\n",
    "    with open('./config.yaml', \"w\") as ff:\n",
    "        yaml.dump(config, ff, default_flow_style=False)\n",
    "\n",
    "    !python3 train.py -y './config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in listdir('./runs') if isfile(join('./runs', f))]\n",
    "config_list = []\n",
    "\n",
    "graph = {'tfidf':[0,0], 'doc2vec':[0,0], 'bert':[0,0]}\n",
    "for fx in files:\n",
    "    f = './runs/' + fx\n",
    "    with open(f, \"rb\") as file:\n",
    "        config = pickle.load(file)\n",
    "        if config['args']['lowercase']:\n",
    "            graph[config['model']][1] = [config['output']]\n",
    "        else:\n",
    "            graph[config['model']][0] = [config['output']]\n",
    "    config_list += [config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf': [[0.5043794755752165], [0.4591584867338468]],\n",
       " 'doc2vec': [[0.4940810799598694], [0.5658628433942795]],\n",
       " 'bert': [[0.9015057206153869], [0.9123975753784179]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/graph_data.pkl', \"wb\") as pickleFile:\n",
    "    pickle.dump(graph, pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'data_path': './data/raw/sample.csv',\n",
       "   'lemmatize': True,\n",
       "   'lowercase': True,\n",
       "   'model_dir': './models/',\n",
       "   'remove_punctuation': True,\n",
       "   'remove_stopwords': True,\n",
       "   'save_model': False,\n",
       "   'save_validation': True,\n",
       "   'validation_dir': './runs/'},\n",
       "  'model': 'tfidf',\n",
       "  'output': 0.4591584867338468},\n",
       " {'args': {'data_path': './data/raw/sample.csv',\n",
       "   'lemmatize': False,\n",
       "   'lowercase': False,\n",
       "   'model_dir': './models/',\n",
       "   'remove_punctuation': False,\n",
       "   'remove_stopwords': False,\n",
       "   'save_model': False,\n",
       "   'save_validation': True,\n",
       "   'validation_dir': './runs/'},\n",
       "  'model': 'tfidf',\n",
       "  'output': 0.5043794755752165},\n",
       " {'args': {'data_path': './data/raw/sample.csv',\n",
       "   'lemmatize': True,\n",
       "   'lowercase': True,\n",
       "   'model_dir': './models/',\n",
       "   'remove_punctuation': True,\n",
       "   'remove_stopwords': True,\n",
       "   'save_model': False,\n",
       "   'save_validation': True,\n",
       "   'validation_dir': './runs/'},\n",
       "  'model': 'bert',\n",
       "  'output': 0.9123975753784179},\n",
       " {'args': {'data_path': './data/raw/sample.csv',\n",
       "   'lemmatize': False,\n",
       "   'lowercase': False,\n",
       "   'model_dir': './models/',\n",
       "   'remove_punctuation': False,\n",
       "   'remove_stopwords': False,\n",
       "   'save_model': False,\n",
       "   'save_validation': True,\n",
       "   'validation_dir': './runs/'},\n",
       "  'model': 'doc2vec',\n",
       "  'output': 0.4940810799598694},\n",
       " {'args': {'data_path': './data/raw/sample.csv',\n",
       "   'lemmatize': True,\n",
       "   'lowercase': True,\n",
       "   'model_dir': './models/',\n",
       "   'remove_punctuation': True,\n",
       "   'remove_stopwords': True,\n",
       "   'save_model': False,\n",
       "   'save_validation': True,\n",
       "   'validation_dir': './runs/'},\n",
       "  'model': 'doc2vec',\n",
       "  'output': 0.5658628433942795},\n",
       " {'args': {'data_path': './data/raw/sample.csv',\n",
       "   'lemmatize': False,\n",
       "   'lowercase': False,\n",
       "   'model_dir': './models/',\n",
       "   'remove_punctuation': False,\n",
       "   'remove_stopwords': False,\n",
       "   'save_model': False,\n",
       "   'save_validation': True,\n",
       "   'validation_dir': './runs/'},\n",
       "  'model': 'bert',\n",
       "  'output': 0.9015057206153869}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudwine",
   "language": "python",
   "name": "cloudwine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
